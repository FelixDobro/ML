{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from xmlrpc.client import DateTime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from fontTools.misc.bezierTools import namedtuple\n",
    "from torch.cuda import device\n",
    "\n",
    "input_files = glob.glob('data/train/input*.csv')\n",
    "output_files = glob.glob('data/train/output*.csv')\n",
    "\n",
    "input_df = pd.concat((pd.read_csv(f) for f in input_files), ignore_index=True)\n",
    "output_df = pd.concat((pd.read_csv(f) for f in output_files), ignore_index=True)\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Redefining columns\n",
    "\n",
    "one_hot_columsns = [\"play_direction\", \"player_position\", \"player_side\", \"player_role\"]\n",
    "input_df = pd.get_dummies(input_df, columns=one_hot_columsns)\n",
    "input_df = input_df.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])\n",
    "output_df = output_df.sort_values([\"game_id\", \"play_id\", \"nfl_id\", \"frame_id\"])"
   ],
   "id": "abbf4699d199e462",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Transforming input data\n",
    "\n",
    "\n",
    "\n",
    "## Age\n",
    "\n",
    "year = 2025\n",
    "input_df[\"player_birth_date\"] = pd.to_datetime(input_df[\"player_birth_date\"])\n",
    "input_df[\"age\"] = 2025 - input_df[\"player_birth_date\"].dt.year\n",
    "\n",
    "## Height to meters\n",
    "\n",
    "def foot_to_meters(x:str):\n",
    "    x = x.replace(\"-\",\".\")\n",
    "    meters = float(x) * 0.3048\n",
    "    return meters\n",
    "\n",
    "input_df[\"player_height\"] = input_df[\"player_height\"].apply(foot_to_meters)\n",
    "input_df[\"player_height\"] = pd.to_numeric(input_df[\"player_height\"])"
   ],
   "id": "6bbde74c04385f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Scaling Inputs\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaled_columns= [\"absolute_yardline_number\", \"player_height\", \"player_weight\", \"age\", \"s\", \"a\", \"dir\", \"o\", \"ball_land_x\", \"ball_land_y\"]\n",
    "scaler = StandardScaler()\n",
    "input_df[scaled_columns] = scaler.fit_transform(input_df[scaled_columns])"
   ],
   "id": "8f09a00312004fe5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Defining feature columns\n",
    "\n",
    "feature_columns = []\n",
    "for c in input_df.columns:\n",
    "    for columns in one_hot_columsns:\n",
    "        if c.startswith(columns) and c not in one_hot_columsns:\n",
    "            feature_columns.append(c)\n",
    "feature_columns.append(\"absolute_yardline_number\")\n",
    "feature_columns.append(\"player_height\")\n",
    "feature_columns.append(\"player_weight\")\n",
    "feature_columns.append(\"age\")\n",
    "feature_columns.append(\"x\")\n",
    "feature_columns.append(\"y\")\n",
    "feature_columns.append(\"s\")\n",
    "feature_columns.append(\"a\")\n",
    "feature_columns.append(\"dir\")\n",
    "feature_columns.append(\"o\")\n",
    "feature_columns.append(\"ball_land_x\")\n",
    "feature_columns.append(\"ball_land_y\")\n",
    "\n",
    "label_columns = [\"x\", \"y\"]"
   ],
   "id": "2369bdb4b07b63fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sequence_groups = [\"game_id\", \"play_id\", \"nfl_id\"]\n",
    "groups_input = input_df[input_df[\"player_to_predict\"]].groupby(sequence_groups)\n",
    "groups_output = output_df.groupby(sequence_groups)\n",
    "max_input_sequence = groups_input.size().max()\n",
    "max_output_sequence = groups_output.size().max()"
   ],
   "id": "bec070e9ea204e1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Extracting sequences in shape of [total_sequences, len_sequences, vector_length]\n",
    "\n",
    "\n",
    "feature_dim = len(feature_columns)\n",
    "out_dim = len(label_columns)\n",
    "input_sequences = []\n",
    "output_sequences = []\n",
    "\n",
    "i = 0\n",
    "for (game_id, play_id, nfl_id), frame in groups_input:\n",
    "    i += 1\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    input_sequence = frame[feature_columns].to_numpy(dtype=np.float32)\n",
    "    group = groups_output.get_group((game_id, play_id, nfl_id))\n",
    "    output_sequence = group[label_columns].to_numpy(dtype=np.float32)\n",
    "    input_sequences.append(input_sequence)\n",
    "    output_sequences.append(output_sequence)"
   ],
   "id": "90e0d52ea804e40c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "from collections import namedtuple\n",
    "from typing import NamedTuple\n",
    "\n",
    "class DataSetEntry(NamedTuple):\n",
    "    input_sequence: any\n",
    "    output_sequences: any\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, input_sequences, how_many):\n",
    "        self.input_sequences = input_sequences\n",
    "        self.how_many = how_many\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_sequences[idx], self.how_many[idx]\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, input_sequences,output_sequences):\n",
    "        self.sequences = input_sequences\n",
    "\n",
    "        self.labels = output_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return DataSetEntry(self.sequences[idx], self.labels[idx])"
   ],
   "id": "e926177026e97a18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(batch):\n",
    "    max_len_in_seq = max(len(e.input_sequence) for e in batch)\n",
    "    max_len_out_seq = max(len(e.output_sequences) for e in batch)\n",
    "    lengths_in = []\n",
    "    lengths_out = []\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "    x,y = 31,32\n",
    "    last_coordinates = []\n",
    "    for entry in batch:\n",
    "        inputs = entry.input_sequence\n",
    "        last_coordinates.append([inputs[-1][x], inputs[-1][y]])\n",
    "        outputs = entry.output_sequences\n",
    "        lengths_in.append(len(inputs))\n",
    "        lengths_out.append(len(outputs))\n",
    "        padding_in = max_len_in_seq - len(inputs)\n",
    "        if padding_in > 0:\n",
    "            inputs = np.concatenate([inputs, np.zeros((padding_in, inputs.shape[1]))])\n",
    "        input_seq.append(inputs)\n",
    "        padding_out = max_len_out_seq- len(outputs)\n",
    "        if padding_out > 0:\n",
    "            outputs = np.concatenate([outputs, np.zeros((padding_out, outputs.shape[1]))])\n",
    "        output_seq.append(outputs)\n",
    "\n",
    "    input_seq = torch.tensor(np.array(input_seq), dtype=torch.float32)\n",
    "    output_seq = torch.tensor(np.array(output_seq), dtype=torch.float32)\n",
    "    lengths_in = torch.tensor(np.array(lengths_in), dtype=torch.long)\n",
    "    lengths_out = torch.tensor(np.array(lengths_out), dtype=torch.long)\n",
    "    last_coordinates = torch.tensor(np.array(last_coordinates), dtype=torch.float32)\n",
    "    return input_seq, output_seq, lengths_in, lengths_out, last_coordinates"
   ],
   "id": "f51bc7d97f9e8795",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = SequenceDataset(input_sequences, output_sequences)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, collate_fn=collate_fn)"
   ],
   "id": "b5d26648a3120ac3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch = next(iter(dataloader))",
   "id": "d4a93bda080b8efc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "in_seq, out_seq, lengths_in, lengths_out, last_cords = batch",
   "id": "eda0b138a3c95b7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim, emedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, emedding_dim),\n",
    "        )\n",
    "\n",
    "        self.warm_gru = nn.GRU(emedding_dim, hidden_size=hidden_dim, num_layers=1, batch_first=True)\n",
    "\n",
    "        self.predict_gru = nn.GRUCell(2, hidden_dim)\n",
    "\n",
    "        self.predict_cords = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, batch, device):\n",
    "        if len(batch) == 4:\n",
    "            in_seq, lengths_in, lengths_out, last_cords = batch\n",
    "        else:\n",
    "            in_seq, out_seq, lengths_in, lengths_out, last_cords = batch\n",
    "        in_seq = in_seq.to(device)\n",
    "        lengths_out = lengths_out.to(device)\n",
    "        last_cords = last_cords.to(device)\n",
    "\n",
    "        x = self.embedder(in_seq)\n",
    "        x = pack_padded_sequence(x, lengths_in, batch_first=True, enforce_sorted=False)\n",
    "        out, hidden = self.warm_gru(x)\n",
    "        hidden = hidden.squeeze(0)\n",
    "        predictions = []\n",
    "        time_steps = lengths_out.max().item()\n",
    "\n",
    "        for t in range(time_steps):\n",
    "            # Schritt 1: aktive Sequenzen bestimmen\n",
    "            active_mask = (t < lengths_out).float().unsqueeze(1)  # (B, 1)\n",
    "\n",
    "            # Schritt 2: GRU-Schritt NUR für aktive Einträge\n",
    "            hidden = self.predict_gru(last_cords, hidden)\n",
    "            last_cords = self.predict_cords(hidden)\n",
    "\n",
    "            # Schritt 3: Tote Sequenzen einfrieren\n",
    "            hidden = hidden * active_mask + hidden.detach() * (1 - active_mask)\n",
    "            last_cords = last_cords * active_mask  # padding bleibt 0, wenn inactive\n",
    "\n",
    "            predictions.append(last_cords)\n",
    "        predictions = torch.stack(predictions).permute(1,0,2)  # (T, B, 2)\n",
    "\n",
    "        return predictions\n"
   ],
   "id": "564d75516e2bc345",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = Net(39, 32, 256)",
   "id": "b182ebc4906e7d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "input_seq, output_seq, lengths_in, lengths_out, last_coordinates = batch",
   "id": "9a29977a13b8d756",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(input_seq.shape)\n",
    "print(output_seq.shape)"
   ],
   "id": "5e01e16e0dc63781",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch.optim\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "model.train()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(100000):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        out = model(batch, device)\n",
    "        _, label, _,_,_= batch\n",
    "\n",
    "        label = label.to(device)\n",
    "        loss = F.mse_loss(out, label)\n",
    "        total_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"epoch\", epoch)\n",
    "    print(\"loss\", total_loss)"
   ],
   "id": "88c229ae407663d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50\n",
      "loss 183.74715238809586\n",
      "epoch 51\n",
      "loss 178.31585256755352\n",
      "epoch 52\n",
      "loss 180.97881653904915\n",
      "epoch 53\n",
      "loss 171.63280817121267\n",
      "epoch 54\n",
      "loss 170.21660748124123\n",
      "epoch 55\n",
      "loss 171.16558840870857\n",
      "epoch 56\n",
      "loss 170.0693806707859\n",
      "epoch 57\n",
      "loss 164.01170954108238\n",
      "epoch 58\n",
      "loss 173.82015446573496\n",
      "epoch 59\n",
      "loss 166.6525504142046\n",
      "epoch 60\n",
      "loss 162.1146363914013\n",
      "epoch 61\n",
      "loss 166.312862098217\n",
      "epoch 62\n",
      "loss 153.54504086077213\n",
      "epoch 63\n",
      "loss 155.7516399770975\n",
      "epoch 64\n",
      "loss 160.19923071563244\n",
      "epoch 65\n",
      "loss 156.0485179722309\n",
      "epoch 66\n",
      "loss 155.11151158809662\n",
      "epoch 67\n",
      "loss 159.80404154211283\n",
      "epoch 68\n",
      "loss 151.65920859575272\n",
      "epoch 69\n",
      "loss 156.58521324396133\n",
      "epoch 70\n",
      "loss 149.28959594666958\n",
      "epoch 71\n",
      "loss 152.73282431066036\n",
      "epoch 72\n",
      "loss 149.62779155373573\n",
      "epoch 73\n",
      "loss 147.0765001475811\n",
      "epoch 74\n",
      "loss 154.3054859265685\n",
      "epoch 75\n",
      "loss 146.01862820237875\n",
      "epoch 76\n",
      "loss 144.57381862401962\n",
      "epoch 77\n",
      "loss 146.59786561131477\n",
      "epoch 78\n",
      "loss 145.31237460672855\n",
      "epoch 79\n",
      "loss 138.1667341440916\n",
      "epoch 80\n",
      "loss 138.47759246826172\n",
      "epoch 81\n",
      "loss 139.28719380497932\n",
      "epoch 82\n",
      "loss 142.43640758097172\n",
      "epoch 83\n",
      "loss 138.77420412749052\n",
      "epoch 84\n",
      "loss 138.42937910556793\n",
      "epoch 85\n",
      "loss 138.07549771666527\n",
      "epoch 86\n",
      "loss 142.8259158656001\n",
      "epoch 87\n",
      "loss 139.34633615612984\n",
      "epoch 88\n",
      "loss 132.39870196580887\n",
      "epoch 89\n",
      "loss 139.9786734879017\n",
      "epoch 90\n",
      "loss 137.03228472173214\n",
      "epoch 91\n",
      "loss 134.17571526765823\n",
      "epoch 92\n",
      "loss 133.95451387763023\n",
      "epoch 93\n",
      "loss 132.8605117201805\n",
      "epoch 94\n",
      "loss 131.4812324643135\n",
      "epoch 95\n",
      "loss 132.38723880052567\n",
      "epoch 96\n",
      "loss 132.4677804261446\n",
      "epoch 97\n",
      "loss 135.9949240460992\n",
      "epoch 98\n",
      "loss 127.29114897549152\n",
      "epoch 99\n",
      "loss 128.7913807556033\n",
      "epoch 100\n",
      "loss 128.49730797857046\n",
      "epoch 101\n",
      "loss 132.81200297921896\n",
      "epoch 102\n",
      "loss 127.88842510432005\n",
      "epoch 103\n",
      "loss 127.06885977834463\n",
      "epoch 104\n",
      "loss 127.79205946624279\n",
      "epoch 105\n",
      "loss 128.39940197765827\n",
      "epoch 106\n",
      "loss 126.30090184509754\n",
      "epoch 107\n",
      "loss 128.66698265820742\n",
      "epoch 108\n",
      "loss 122.33098423480988\n",
      "epoch 109\n",
      "loss 123.70125319063663\n",
      "epoch 110\n",
      "loss 122.35827350616455\n",
      "epoch 111\n",
      "loss 125.2322250008583\n",
      "epoch 112\n",
      "loss 129.8383688405156\n",
      "epoch 113\n",
      "loss 123.69700471311808\n",
      "epoch 114\n",
      "loss 124.53699680417776\n",
      "epoch 115\n",
      "loss 119.70183891057968\n",
      "epoch 116\n",
      "loss 123.53402179479599\n",
      "epoch 117\n",
      "loss 122.2659759670496\n",
      "epoch 118\n",
      "loss 126.03526668250561\n",
      "epoch 119\n",
      "loss 119.09918329119682\n",
      "epoch 120\n",
      "loss 121.3280873298645\n",
      "epoch 121\n",
      "loss 122.01866525411606\n",
      "epoch 122\n",
      "loss 121.85342239588499\n",
      "epoch 123\n",
      "loss 118.2354194521904\n",
      "epoch 124\n",
      "loss 118.46422684192657\n",
      "epoch 125\n",
      "loss 118.3596808463335\n",
      "epoch 126\n",
      "loss 118.09994960576296\n",
      "epoch 127\n",
      "loss 118.58865363150835\n",
      "epoch 128\n",
      "loss 113.27417599409819\n",
      "epoch 129\n",
      "loss 117.29942823946476\n",
      "epoch 130\n",
      "loss 113.67954804003239\n",
      "epoch 131\n",
      "loss 117.0915874838829\n",
      "epoch 132\n",
      "loss 117.08591731637716\n",
      "epoch 133\n",
      "loss 113.5484925583005\n",
      "epoch 134\n",
      "loss 114.52462735027075\n",
      "epoch 135\n",
      "loss 113.18580438196659\n",
      "epoch 136\n",
      "loss 114.4915728867054\n",
      "epoch 137\n",
      "loss 114.58227553218603\n",
      "epoch 138\n",
      "loss 112.66851316392422\n",
      "epoch 139\n",
      "loss 114.59623482823372\n",
      "epoch 140\n",
      "loss 111.03201468288898\n",
      "epoch 141\n",
      "loss 110.10062286257744\n",
      "epoch 142\n",
      "loss 112.44295970350504\n",
      "epoch 143\n",
      "loss 111.84037712961435\n",
      "epoch 144\n",
      "loss 109.03303734213114\n",
      "epoch 145\n",
      "loss 106.37612473219633\n",
      "epoch 146\n",
      "loss 110.96622347831726\n",
      "epoch 147\n",
      "loss 107.62220753729343\n",
      "epoch 148\n",
      "loss 106.79027664661407\n",
      "epoch 149\n",
      "loss 107.75099963694811\n",
      "epoch 150\n",
      "loss 105.57161224633455\n",
      "epoch 151\n",
      "loss 105.6607606858015\n",
      "epoch 152\n",
      "loss 108.88278392702341\n",
      "epoch 153\n",
      "loss 101.3781673759222\n",
      "epoch 154\n",
      "loss 102.96683053672314\n",
      "epoch 155\n",
      "loss 106.22712203860283\n",
      "epoch 156\n",
      "loss 104.04063655436039\n",
      "epoch 157\n",
      "loss 102.67192460596561\n",
      "epoch 158\n",
      "loss 100.89860003441572\n",
      "epoch 159\n",
      "loss 104.00301660597324\n",
      "epoch 160\n",
      "loss 101.6057359278202\n",
      "epoch 161\n",
      "loss 104.12800630182028\n",
      "epoch 162\n",
      "loss 103.86165629327297\n",
      "epoch 163\n",
      "loss 101.13366278260946\n",
      "epoch 164\n",
      "loss 100.82355391979218\n",
      "epoch 165\n",
      "loss 99.69485477358103\n",
      "epoch 166\n",
      "loss 101.9256854839623\n",
      "epoch 167\n",
      "loss 96.9978823363781\n",
      "epoch 168\n",
      "loss 98.97374937683344\n",
      "epoch 169\n",
      "loss 100.80562746524811\n",
      "epoch 170\n",
      "loss 97.37173552811146\n",
      "epoch 171\n",
      "loss 99.30772102624178\n",
      "epoch 172\n",
      "loss 96.9756003394723\n",
      "epoch 173\n",
      "loss 97.23586260527372\n",
      "epoch 174\n",
      "loss 98.22018046677113\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 10\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m100000\u001B[39m):\n\u001B[32m      9\u001B[39m     total_loss = \u001B[32m0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m dataloader:\n\u001B[32m     11\u001B[39m         out = model(batch, device)\n\u001B[32m     12\u001B[39m         _, label, _,_,_= batch\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    731\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    732\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    733\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m734\u001B[39m data = \u001B[38;5;28mself\u001B[39m._next_data()\n\u001B[32m    735\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    737\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    739\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    740\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    788\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    789\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m790\u001B[39m     data = \u001B[38;5;28mself\u001B[39m._dataset_fetcher.fetch(index)  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    791\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    792\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:55\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.collate_fn(data)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[22]\u001B[39m\u001B[32m, line 20\u001B[39m, in \u001B[36mcollate_fn\u001B[39m\u001B[34m(batch)\u001B[39m\n\u001B[32m     18\u001B[39m padding_in = max_len_in_seq - \u001B[38;5;28mlen\u001B[39m(inputs)\n\u001B[32m     19\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m padding_in > \u001B[32m0\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m20\u001B[39m     inputs = np.concatenate([inputs, np.zeros((padding_in, inputs.shape[\u001B[32m1\u001B[39m]))])\n\u001B[32m     21\u001B[39m input_seq.append(inputs)\n\u001B[32m     22\u001B[39m padding_out = max_len_out_seq- \u001B[38;5;28mlen\u001B[39m(outputs)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\async_helpers.py:128\u001B[39m, in \u001B[36m_pseudo_sync_runner\u001B[39m\u001B[34m(coro)\u001B[39m\n\u001B[32m    120\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    121\u001B[39m \u001B[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001B[39;00m\n\u001B[32m    122\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    125\u001B[39m \u001B[33;03mCredit to Nathaniel Smith\u001B[39;00m\n\u001B[32m    126\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     coro.send(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[32m    130\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m exc.value\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3381\u001B[39m, in \u001B[36mInteractiveShell.run_cell_async\u001B[39m\u001B[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001B[39m\n\u001B[32m   3377\u001B[39m exec_count = \u001B[38;5;28mself\u001B[39m.execution_count\n\u001B[32m   3378\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m result.error_in_exec:\n\u001B[32m   3379\u001B[39m     \u001B[38;5;66;03m# Store formatted traceback and error details\u001B[39;00m\n\u001B[32m   3380\u001B[39m     \u001B[38;5;28mself\u001B[39m.history_manager.exceptions[exec_count] = (\n\u001B[32m-> \u001B[39m\u001B[32m3381\u001B[39m         \u001B[38;5;28mself\u001B[39m._format_exception_for_storage(result.error_in_exec)\n\u001B[32m   3382\u001B[39m     )\n\u001B[32m   3384\u001B[39m \u001B[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001B[39;00m\n\u001B[32m   3385\u001B[39m \u001B[38;5;28mself\u001B[39m.execution_count += \u001B[32m1\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3435\u001B[39m, in \u001B[36mInteractiveShell._format_exception_for_storage\u001B[39m\u001B[34m(self, exception, filename, running_compiled_code)\u001B[39m\n\u001B[32m   3432\u001B[39m         stb = evalue._render_traceback_()\n\u001B[32m   3433\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   3434\u001B[39m         \u001B[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m3435\u001B[39m         stb = \u001B[38;5;28mself\u001B[39m.InteractiveTB.structured_traceback(\n\u001B[32m   3436\u001B[39m             etype, evalue, tb, tb_offset=\u001B[32m1\u001B[39m\n\u001B[32m   3437\u001B[39m         )\n\u001B[32m   3438\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[32m   3439\u001B[39m     \u001B[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001B[39;00m\n\u001B[32m   3440\u001B[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1182\u001B[39m, in \u001B[36mAutoFormattedTB.structured_traceback\u001B[39m\u001B[34m(self, etype, evalue, etb, tb_offset, context)\u001B[39m\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m   1181\u001B[39m     \u001B[38;5;28mself\u001B[39m.tb = etb\n\u001B[32m-> \u001B[39m\u001B[32m1182\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m FormattedTB.structured_traceback(\n\u001B[32m   1183\u001B[39m     \u001B[38;5;28mself\u001B[39m, etype, evalue, etb, tb_offset, context\n\u001B[32m   1184\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:1053\u001B[39m, in \u001B[36mFormattedTB.structured_traceback\u001B[39m\u001B[34m(self, etype, evalue, etb, tb_offset, context)\u001B[39m\n\u001B[32m   1050\u001B[39m mode = \u001B[38;5;28mself\u001B[39m.mode\n\u001B[32m   1051\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose_modes:\n\u001B[32m   1052\u001B[39m     \u001B[38;5;66;03m# Verbose modes need a full traceback\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1053\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m VerboseTB.structured_traceback(\n\u001B[32m   1054\u001B[39m         \u001B[38;5;28mself\u001B[39m, etype, evalue, etb, tb_offset, context\n\u001B[32m   1055\u001B[39m     )\n\u001B[32m   1056\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m mode == \u001B[33m\"\u001B[39m\u001B[33mDocs\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m   1057\u001B[39m     \u001B[38;5;66;03m# return DocTB\u001B[39;00m\n\u001B[32m   1058\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m DocTB(\n\u001B[32m   1059\u001B[39m         theme_name=\u001B[38;5;28mself\u001B[39m._theme_name,\n\u001B[32m   1060\u001B[39m         call_pdb=\u001B[38;5;28mself\u001B[39m.call_pdb,\n\u001B[32m   (...)\u001B[39m\u001B[32m   1068\u001B[39m         etype, evalue, etb, tb_offset, \u001B[32m1\u001B[39m\n\u001B[32m   1069\u001B[39m     )  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:861\u001B[39m, in \u001B[36mVerboseTB.structured_traceback\u001B[39m\u001B[34m(self, etype, evalue, etb, tb_offset, context)\u001B[39m\n\u001B[32m    852\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mstructured_traceback\u001B[39m(\n\u001B[32m    853\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    854\u001B[39m     etype: \u001B[38;5;28mtype\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    858\u001B[39m     context: \u001B[38;5;28mint\u001B[39m = \u001B[32m5\u001B[39m,\n\u001B[32m    859\u001B[39m ) -> \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    860\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m861\u001B[39m     formatted_exceptions: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m]] = \u001B[38;5;28mself\u001B[39m.format_exception_as_a_whole(\n\u001B[32m    862\u001B[39m         etype, evalue, etb, context, tb_offset\n\u001B[32m    863\u001B[39m     )\n\u001B[32m    865\u001B[39m     termsize = \u001B[38;5;28mmin\u001B[39m(\u001B[32m75\u001B[39m, get_terminal_size()[\u001B[32m0\u001B[39m])\n\u001B[32m    866\u001B[39m     theme = theme_table[\u001B[38;5;28mself\u001B[39m._theme_name]\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:746\u001B[39m, in \u001B[36mVerboseTB.format_exception_as_a_whole\u001B[39m\u001B[34m(self, etype, evalue, etb, context, tb_offset)\u001B[39m\n\u001B[32m    744\u001B[39m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(tb_offset, \u001B[38;5;28mint\u001B[39m)\n\u001B[32m    745\u001B[39m head = \u001B[38;5;28mself\u001B[39m.prepare_header(\u001B[38;5;28mstr\u001B[39m(etype), \u001B[38;5;28mself\u001B[39m.long_header)\n\u001B[32m--> \u001B[39m\u001B[32m746\u001B[39m records = \u001B[38;5;28mself\u001B[39m.get_records(etb, context, tb_offset) \u001B[38;5;28;01mif\u001B[39;00m etb \u001B[38;5;28;01melse\u001B[39;00m []\n\u001B[32m    748\u001B[39m frames = []\n\u001B[32m    749\u001B[39m skipped = \u001B[32m0\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\miniconda3\\Lib\\site-packages\\IPython\\core\\ultratb.py:830\u001B[39m, in \u001B[36mVerboseTB.get_records\u001B[39m\u001B[34m(self, etb, context, tb_offset)\u001B[39m\n\u001B[32m    828\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[32m    829\u001B[39m     max_len = \u001B[32m0\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m830\u001B[39m max_len = \u001B[38;5;28mmax\u001B[39m(max_len, max_len)\n\u001B[32m    831\u001B[39m tbs.append(cf)\n\u001B[32m    832\u001B[39m cf = \u001B[38;5;28mgetattr\u001B[39m(cf, \u001B[33m\"\u001B[39m\u001B[33mtb_next\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"checkpoints/single_player_traj/model1.pt\")",
   "id": "a308cdd9b384bb83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, collate_fn=collate_fn)",
   "id": "62939c8706b8dc0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch = next(iter(dataloader))\n",
    "predict = model(batch, device)"
   ],
   "id": "729c4af656624c76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predict = predict.cpu().detach().numpy()\n",
    "predict_x = predict[:,:,0].flatten()\n",
    "predict_y = predict[:,:,1].flatten()\n",
    "prediction = pd.DataFrame()\n",
    "prediction['x'] = predict_x\n",
    "prediction['y'] = predict_y\n",
    "prediction"
   ],
   "id": "2540304054813ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_,l,_,_,_= batch",
   "id": "ef6fa6a3add8b172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_l = l[:,:,0].flatten()\n",
    "y_l = l[:,:,1].flatten()\n",
    "label = pd.DataFrame()\n",
    "label['x'] = x_l\n",
    "label['y'] = y_l\n",
    "label"
   ],
   "id": "35111d07fa948f19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "test_output = pd.read_csv('data/test.csv')\n",
    "test_input = pd.read_csv('data/test_input.csv')"
   ],
   "id": "59159a74a80c52eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from functions import *\n",
    "\n",
    "test_input = transform_df(test_input)"
   ],
   "id": "234beaf3db23446a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_input[scaled_columns] = scaler.transform(test_input[scaled_columns])",
   "id": "cf3894f5d45a030b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "player_position_K = []\n",
    "player_position_LB = []\n",
    "player_position_P = []\n",
    "player_position_T = []\n",
    "\n",
    "for i in range(len(test_input)):\n",
    "    player_position_T.append(False)\n",
    "    player_position_LB.append(False)\n",
    "    player_position_P.append(False)\n",
    "    player_position_K.append(False)\n",
    "\n",
    "test_input[\"player_position_K\"] = player_position_K\n",
    "test_input[\"player_position_LB\"] = player_position_LB\n",
    "test_input[\"player_position_P\"] = player_position_P\n",
    "test_input[\"player_position_T\"] = player_position_T\n"
   ],
   "id": "c4a7cf81681caaeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def train_collate_fn(batch):\n",
    "    input_sequences, lengths = zip(*batch)\n",
    "    max_len_in_seq = max(len(input_sequence) for input_sequence in input_sequences)\n",
    "\n",
    "    lengths_in = []\n",
    "\n",
    "    input_seq = []\n",
    "\n",
    "    x,y = 31,32\n",
    "    last_coordinates = []\n",
    "    for inputs in input_sequences:\n",
    "        last_coordinates.append([inputs[-1][x], inputs[-1][y]])\n",
    "\n",
    "        lengths_in.append(len(inputs))\n",
    "\n",
    "        padding_in = max_len_in_seq - len(inputs)\n",
    "        if padding_in > 0:\n",
    "            inputs = np.concatenate([inputs, np.zeros((padding_in, inputs.shape[1]))])\n",
    "        input_seq.append(inputs)\n",
    "\n",
    "\n",
    "    input_seq = torch.tensor(np.array(input_seq), dtype=torch.float32)\n",
    "    lengths_in = torch.tensor(np.array(lengths_in), dtype=torch.long)\n",
    "    lengths_out = torch.tensor(np.array(lengths), dtype=torch.long).squeeze(1)\n",
    "    last_coordinates = torch.tensor(np.array(last_coordinates), dtype=torch.float32)\n",
    "    return input_seq, lengths_in, lengths_out, last_coordinates"
   ],
   "id": "38de361516a8ebfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def single_player_trajectory(input_df, group_in, output_df, feature_columns):\n",
    "    groups_input = input_df[input_df[\"player_to_predict\"]].groupby(group_in)\n",
    "    groups_output = output_df.groupby(group_in)\n",
    "    how_many = []\n",
    "\n",
    "    input_sequences = []\n",
    "\n",
    "    i = 0\n",
    "    for (game_id, play_id, nfl_id), frame in groups_input:\n",
    "        i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "        input_sequence = frame[feature_columns].to_numpy(dtype=np.float32)\n",
    "        input_sequences.append(input_sequence)\n",
    "        how_many.append(frame[\"num_frames_output\"].unique())\n",
    "\n",
    "    ids = (\n",
    "            output_df[\"game_id\"].astype(str) + \"_\" +\n",
    "            output_df[\"play_id\"].astype(str) + \"_\" +\n",
    "            output_df[\"nfl_id\"].astype(str) + \"_\" +\n",
    "            output_df[\"frame_id\"].astype(str)\n",
    "    ).tolist()\n",
    "    output_df = pd.DataFrame({\"id\": ids})\n",
    "    return input_sequences, output_df, how_many"
   ],
   "id": "6c6e5ae97d036df4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "input_sequences, result_df, how_many = single_player_trajectory(test_input, sequence_groups, test_output, feature_columns)\n",
   "id": "1cc6055b0e65e091",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "dataset = TrainDataset(input_sequences, how_many)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=train_collate_fn)"
   ],
   "id": "8389f96c784905bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "batch = next(iter(dataloader))",
   "id": "8a5c56869e6d4980",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = Net(39, 32, 128)\n",
    "model.load_state_dict(torch.load('checkpoints/single_player_traj/model1.pt'))\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ],
   "id": "3f98483f489aac07",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_x = []\n",
    "result_y = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_seq, lengths_in, lengths_out, last_coordinates = batch\n",
    "        out = model(batch, device)        # erwartet dein Model dieses Tuple? Falls nur x: model(input_seq, ...)\n",
    "        # out: (B, T_max, 2)\n",
    "\n",
    "        out = out.cpu().numpy()\n",
    "        lengths_out = lengths_out.cpu().numpy()\n",
    "\n",
    "        # Nur die ersten length_i Schritte je Sample nehmen\n",
    "        for i in range(out.shape[0]):\n",
    "            t = int(lengths_out[i])\n",
    "            result_x.extend(out[i, :t, 0])\n",
    "            result_y.extend(out[i, :t, 1])"
   ],
   "id": "64dfd17e060243fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result_df[\"x\"] = result_x\n",
    "result_df[\"y\"] = result_y"
   ],
   "id": "51b750b0297faa1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "inseq, _, _,_ = batch",
   "id": "59cffb319cbb349c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x = inseq[0,:,31]\n",
    "y = inseq[0,:,32]"
   ],
   "id": "404626e4865be47c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_input[test_input[\"nfl_id\"] == 54586]",
   "id": "6255bc65ada2b014",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "result_df.to_csv(\"first_submission.csv\", index=False)",
   "id": "1b48bf7001c4ba35",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
